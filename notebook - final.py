# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u_ZRZHCsQiQ5npaCedHPf5Ivj6zb00j7

# Predictive Analysis of Student Depression Dataset

Problem Statements

- Bagaimana membangun model prediksi untuk mengidentifikasi mahasiswa yang mengalami depresi berdasarkan data demografi, akademik, dan gaya hidup?
- Faktor-faktor apa saja yang paling signifikan dalam memengaruhi tingkat depresi pada mahasiswa?
- Algoritma machine learning mana yang menunjukkan performa terbaik dalam mengklasifikasikan status depresi mahasiswa?

## Import Library
"""

# Data handling & visualization
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import gdown

# Visual style settings
sns.set(style='whitegrid')
plt.style.use('seaborn-v0_8-whitegrid')

# Preprocessing & splitting
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Classifiers
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Evaluation metrics
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay
)

# Hyperparameter tuning
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform

# Warning control
import warnings
warnings.filterwarnings("ignore")

"""## Exploratory Data Analysis (EDA)"""

# Mengunduh FIle
file_id = '1gCo9QoXnZzkgN4ePIAz07SRDxSIN0Wlp'
url = f'https://drive.google.com/uc?id={file_id}'

gdown.download(url, 'student_depression_dataset.csv', quiet=False)

# Load Dataset
df = pd.read_csv('student_depression_dataset.csv')
df.head(10)

# Cek Struktur Data
df.info()

"""ada beberapa fitur seperti sleep duration yang perlu dikonversi menjadi numerik, encode fitur kategorikal biner (yes /no), dan drop kolom tidak dibutuhkan."""

# Statistik deskriptif
df.describe()

# Cek missing values
df.isnull().sum()

# Cek Duplikat
duplicates = df[df.duplicated()]
print(duplicates)

# Distribusi target variabel
sns.countplot(x='Depression', data=df)
plt.title('Distribusi Status Depresi')
plt.xlabel('Depresi (0 = Tidak, 1 = Ya)')
plt.ylabel('Jumlah')
plt.show()

print(df['Depression'].value_counts())

# Visualisasi distribusi fitur numerik
numeric_features = df.select_dtypes(include=np.number).columns.tolist()

df[numeric_features].hist(bins=15, figsize=(15, 10), color='#00b4d8')
plt.suptitle('Distribusi Fitur Numerik', fontsize=16)
plt.show()

"""Fitur 'Work Pressure' dan 'Job Satisfaction' nampak hanya ada value di angka nol. Hal tersebut terjadi antara memang mahasiswa tidak ada yang melakukan pekerjaan atau ada nilai selain nol dengan frekuensi sangat kecil sehingga tidak terlihat jelas dalam grafik. Kemudian dilakukan pemeriksaan nilai unik."""

print(df['Work Pressure'].unique())
print(df['Job Satisfaction'].unique())

# Korelasi antar fitur numerik
plt.figure(figsize=(12, 8))
correlation_matrix = df[numeric_features].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)
plt.title('Heatmap Korelasi Fitur Numerik')
plt.show()

"""Heatmap di atas menunjukkan seberapa besar nilai korelasi atau hubungan antara dua fitur numerik. Fitur dengan korelasi cukup kuat ditunjukkan antara 'Academic Pressure' dan 'Depression' dengan arah positif. Dengan kata lain, semakin tinggi atau besar tekanan akademik, maka kemungkinan depresi juga akan meningkat. Hal tersebut sejalan dengan konsep atau teori."""

# Boxplot untuk deteksi outlier
for col in numeric_features:
    plt.figure(figsize=(6, 3))
    sns.boxplot(x=df[col], color='#ff6b6b')
    plt.title(f'Boxplot: {col}')
    plt.show()

plt.hist(df['Age'], bins=10, edgecolor='black')
plt.title('Distribusi Usia (Age)')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

"""Dari hasil visualisasi dengan boxplot dan histogram, terdapat beberapa nilai outlier pada variabel Age yang tampak cukup mencolok. Namun, setelah analisis lanjutan dan mempertimbangkan konteks data, nilai-nilai tersebut tetap dipertahankan dalam dataset. Hal ini dikarenakan terdapat mahasiswa yang memulai pendidikan tinggi di usia yang relatif lebih tua (di atas 24 tahun), sehingga keberadaan nilai ekstrim ini merepresentasikan kondisi nyata di lapangan dan bukan kesalahan pengukuran atau input data. Oleh karena itu, outlier ini tidak dihapus untuk menjaga integritas dan keaslian data."""

# Visualisasi fitur kategorikal terhadap target
categorical_cols = df.select_dtypes(include='object').columns.tolist()
for col in categorical_cols:
    plt.figure(figsize=(6, 3))
    sns.countplot(data=df, x=col, hue='Depression')
    plt.title(f'{col} vs Depression_Status')
    plt.xticks(rotation=30)
    plt.tight_layout()
    plt.show()

"""## Data Preparation"""

df.head()

print(df['Profession'].unique())
print(df['Profession'].value_counts())

"""Fitur yang dianggap tidak relevan sebagai penyebab depresi, fitur dengan low variance, dan berpotensi mirip dengan label akan dihapus."""

# Drop Fitur yang dianggap tidak relevan
df.drop([
    'id',
    'City',
    'Profession',
    'Job Satisfaction',
    'Have you ever had suicidal thoughts ?',
    'Degree'], axis=1, inplace=True)

df.head()

df.info()

print(df['Financial Stress'].value_counts())

# Ganti '?' dengan modus
mode_val = df.loc[df['Financial Stress'] != '?', 'Financial Stress'].mode()[0]
df['Financial Stress'] = df['Financial Stress'].replace('?', mode_val)
df['Financial Stress'] = df['Financial Stress'].astype(float)

# Ubah Tipe Data
df['Financial Stress'] = df['Financial Stress'].astype(float)

# Membersihkan string dari spasi dan tanda kutip
df['Gender'] = df['Gender'].str.strip().str.replace("'", "")
df['Family History of Mental Illness'] = df['Family History of Mental Illness'].str.strip().str.replace("'", "")
df['Sleep Duration'] = df['Sleep Duration'].str.strip().str.replace("'", "")
df['Dietary Habits'] = df['Dietary Habits'].str.strip().str.replace("'", "")

# Encode Fitur Kategorikal

# Label Encoding
df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
df['Family History of Mental Illness'] = df['Family History of Mental Illness'].map({'Yes': 1, 'No': 0})

# Ordinal Encoding
sleep_map = {
    'Less than 5 hours': 0,
    '5-6 hours': 1,
    '7-8 hours': 2,
    'More than 8 hours': 3,
    'Others': 4
}
df['Sleep Duration'] = df['Sleep Duration'].replace(sleep_map)

diet_map = {
    'Unhealthy': 0,
    'Moderate': 1,
    'Healthy': 2,
    'Others': 3
}
df['Dietary Habits'] = df['Dietary Habits'].replace(diet_map)

df.head()

num_cols = ['Age', 'CGPA', 'Work/Study Hours']  # murni numerik

ordinal_cols = ['Academic Pressure', 'Work Pressure', 'Study Satisfaction', 'Financial Stress', 'Sleep Duration'] # bisa juga dikategorikan sebagai numerik ordinal

cat_cols = ['Gender', 'Dietary Habits', 'Family History of Mental Illness']

plt.figure(figsize=(15, 4))

for i, col in enumerate(num_cols):
    plt.subplot(1, len(num_cols), i+1)
    sns.histplot(df[col], bins=30, kde=True)
    plt.title(f'Distribution of {col}')

plt.tight_layout()
plt.show()

# Normalisasi / Standarisasi Fitur Numerik
scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

df.head()

# Memisahkan variabel atau fitur
X = df.drop('Depression', axis=1)
y = df['Depression']

"""## Modelling"""

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Logistic Regression
lr = LogisticRegression(max_iter=1000, random_state=42)
lr.fit(X_train, y_train)

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

"""## Evaluation"""

def evaluate_model(model, X_test, y_test, name="Model"):
    print(f"=== {name} ===")
    y_pred = model.predict(X_test)

    report = classification_report(y_test, y_pred, output_dict=True)
    cm = confusion_matrix(y_test, y_pred)

    disp = ConfusionMatrixDisplay(cm)
    disp.plot(cmap="Blues")
    plt.title(f"Confusion Matrix - {name}")
    plt.show()

    result = {
        "Model": name,
        "Accuracy": report["accuracy"],
        "Precision (macro avg)": report["macro avg"]["precision"],
        "Recall (macro avg)": report["macro avg"]["recall"],
        "F1-score (macro avg)": report["macro avg"]["f1-score"]
    }
    return pd.DataFrame([result])

results = pd.concat([
    evaluate_model(lr, X_test, y_test, "Logistic Regression"),
    evaluate_model(rf, X_test, y_test, "Random Forest")
], ignore_index=True)

print(results)

# Hyperparameter Tuning untuk Logistic Regression dan Random Forest
param_grids = {
    'Logistic Regression': {
        'model': LogisticRegression(max_iter=1000, random_state=42),
        'params': {
            'C': uniform(0.01, 10),
            'solver': ['lbfgs', 'saga'],
            'penalty': ['l2']
        }
    },
    'Random Forest': {
        'model': RandomForestClassifier(random_state=42),
        'params': {
            'n_estimators': [50, 100, 200],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'bootstrap': [True, False]
        }
    }
}

def randomized_tune_and_evaluate(param_grids, X_train, y_train, X_test, y_test, n_iter):
    all_results = []

    for name, mp in param_grids.items():
        print(f"=== Tuning {name} ===")
        rsearch = RandomizedSearchCV(
            estimator=mp['model'],
            param_distributions=mp['params'],
            n_iter=n_iter,
            scoring='f1_macro',
            cv=5,
            n_jobs=-1,
            verbose=2,
            random_state=42
        )
        rsearch.fit(X_train, y_train)
        print(f"Best params for {name}: {rsearch.best_params_}")

        # Evaluasi model terbaik
        eval_df = evaluate_model(rsearch.best_estimator_, X_test, y_test, f"{name} (Tuned)")
        eval_df["Best Params"] = [rsearch.best_params_]
        all_results.append(eval_df)

    final_results = pd.concat(all_results, ignore_index=True)
    print("\n=== Final Tuned Model Evaluation ===")
    print(final_results)

    return final_results

final_tuned_results = randomized_tune_and_evaluate(param_grids, X_train, y_train, X_test, y_test, n_iter=20)

"""## Conclusion

Hasil tuning menunjukkan parameter terbaik untuk masing-masing model sebagai berikut:

- Logistic Regression
  - `C`: 0.017787658410143285
  - `penalty`: `'l2'`
  - `solver`: `'saga'`

- Random Forest
  - `n_estimators`: 50  
  - `min_samples_split`: 5  
  - `min_samples_leaf`: 1  
  - `max_depth`: 10  
  - `bootstrap`: `True`

Hasil Evaluasi Sebelum Tuning

| Model               | Accuracy | Precision (macro avg) | Recall (macro avg) | F1-score (macro avg) |
|---------------------|----------|------------------------|---------------------|----------------------|
| Logistic Regression | 0.796094 | 0.791634               | 0.785142            | 0.787743             |
| Random Forest       | 0.790002 | 0.784341               | 0.780888            | 0.782402             |

Hasil Evaluasi Setelah Tuning

| Model                    | Accuracy | Precision (macro avg) | Recall (macro avg) | F1-score (macro avg) |
|--------------------------|----------|------------------------|---------------------|----------------------|
| Logistic Regression (Tuned) | 0.796811 | 0.792355               | 0.785944            | 0.788520             |
| Random Forest (Tuned)       | 0.792331 | 0.788267               | 0.780224            | 0.783289             |

- Tuning meningkatkan performa model, meskipun tidak signifikan secara drastis.
- Logistic Regression mengalami sedikit peningkatan pada semua metrik, sedangkan Random Forest mendapatkan sedikit peningkatan pada precision dan f1-score.
- Sehingga dalam kasus ini, algoritma Logistic Regression memiliki performa paling baik dalam mengklasifikasikan status depresi mahasiswa
"""